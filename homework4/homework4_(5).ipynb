{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0p2YW70sFJ3",
    "outputId": "b894dca1-f73f-4893-8a85-0b486d32a62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-2ShcyHQsTqE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBFh6RFXKEHI"
   },
   "source": [
    "# LSTM for language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "L252GQ5As4T-",
    "outputId": "b475925e-1870-4ea5-87c8-30bdb6469753"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "device  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ek3V6z2gquTi"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 27):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x2OHuLXZqu-q"
   },
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8NodUypAGm4"
   },
   "source": [
    "## Pride and Prejudice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qets0I7xtS-n"
   },
   "outputs": [],
   "source": [
    "text_all = []\n",
    "with open('prideAndPrejudice.txt') as f:\n",
    "    for line in f:\n",
    "        text_all.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwVi54RxtS-o",
    "outputId": "d6aa5288-6bd8-4907-9ce9-a8a339514cc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.',\n",
       " 'However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.',\n",
       " '\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Netherfield Park is let at last?\"',\n",
       " 'Mr. Bennet replied that he had not.',\n",
       " '\"But it is,\" returned she; \"for Mrs. Long has just been here, and she told me all about it.\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UgxgNrcitS-p"
   },
   "outputs": [],
   "source": [
    "def tokenize(text_all):\n",
    "    text = ' '.join(text_all)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        token = ['<s>'] + nltk.word_tokenize(sent) + ['</s>']\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zcd8eVpZtS-p",
    "outputId": "b6898882-d178-4a92-8094-a74693eadbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "text_tokens = tokenize(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uD7ms5-HlTOG"
   },
   "outputs": [],
   "source": [
    "def get_dict(text_tokens,appear_time=1):\n",
    "    vocab = Counter(sum(text_tokens, []))\n",
    "    # Removing the words that only appear once\n",
    "    vocab = {k:v for k,v in vocab.items() if v>appear_time}\n",
    "    # Sorting the words according to the number of appearances, with the most common word being first\n",
    "    vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "    # Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "    vocab = ['<pad>','<unk>'] + vocab\n",
    "    print(\"vocab number: {}\".format(len(vocab)))\n",
    "    # Dictionaries to store the word to index mappings and vice versa\n",
    "    word2idx = {o:i for i,o in enumerate(vocab)}\n",
    "    idx2word = {i:o for i,o in enumerate(vocab)}\n",
    "\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ep5HhaQLtS-s",
    "outputId": "c8b6db51-2f2a-40a0-d832-31779a782aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab number: 4152\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = get_dict(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZlQlARFqTrJD"
   },
   "outputs": [],
   "source": [
    "# create sequences of length 5 tokens\n",
    "def create_seq(tokens, seq_len = 5):\n",
    "    \n",
    "    sequences = []\n",
    "\n",
    "    if len(tokens) > seq_len:\n",
    "        for i in range(0, len(tokens)-seq_len):\n",
    "            # select sequence of tokens\n",
    "            seq = tokens[i:i+seq_len]\n",
    "            # add to the list\n",
    "            sequences.append(\" \".join(seq))\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    else:\n",
    "        seq = tokens[:]\n",
    "        # pad sequence to 5\n",
    "        for i in range(len(tokens), seq_len):\n",
    "            seq.append('<pad>') \n",
    "        return [\" \".join(seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yrKrmd5xtS-t"
   },
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "    return [word2idx[w] if w in word2idx.keys() else word2idx['<unk>'] for w in seq.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bLxaN0V0tS-t"
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "\n",
    "    def __init__(self, text_tokens, seq_len=5):\n",
    "        seqs = [create_seq(tokens, seq_len) for tokens in text_tokens]\n",
    "        seqs = sum(seqs, [])\n",
    "\n",
    "        # create inputs and targets (x and y)\n",
    "        x, y = [], []\n",
    "\n",
    "        for s in seqs:\n",
    "            x.append(\" \".join(s.split()[:-1]))\n",
    "            y.append(\" \".join(s.split()[1:]))\n",
    "\n",
    "        # convert text sequences to integer sequences\n",
    "        x = [get_integer_seq(i) for i in x]\n",
    "        y = [get_integer_seq(i) for i in y]\n",
    "\n",
    "        # convert lists to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yYfF71omtS-t"
   },
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size=len(word2idx), embed_dim=200, n_hidden=256, n_layers=4, drop_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "\n",
    "        embedded = self.emb_layer(x)\n",
    "        if hidden != None:\n",
    "            lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        else:\n",
    "            lstm_output, hidden = self.lstm(embedded)\n",
    "          \n",
    "        out = self.dropout(lstm_output)\n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uQNabngdtS-u"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs=10, dataloader=None, clip=1, interval=300):\n",
    "    \n",
    "    model.train()\n",
    "    min_loss = 99\n",
    "    for epoch in range(num_epochs):\n",
    "        all_loss = []\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            inputs, targets = x.long().to(device), y.long().to(device)\n",
    "            # hidden = tuple([i.data for i in hidden])\n",
    "\n",
    "            output, hidden = model(inputs, None)\n",
    "            loss = loss_fn(output, targets.view(-1))\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            all_loss.append(loss.item())\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % interval == 0:\n",
    "                print(\"Epoch: {}/{}, Step: {}/{}, Train Loss: {}\".format(epoch+1, num_epochs, i, len(dataloader), loss))\n",
    "        epoch_loss = np.mean(all_loss)\n",
    "        print(\"Epoch: {}/{}, Train Loss: {}\".format(epoch+1, num_epochs, epoch_loss))\n",
    "        \n",
    "        if epoch_loss < min_loss:\n",
    "            torch.save(model.state_dict(), 'model_best.pt')\n",
    "            print('Model saved successfully')\n",
    "            min_loss = epoch_loss\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9hljTczBrCs"
   },
   "source": [
    "## Sequence length: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X7_0qptyBqWH"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = SeqDataset(text_tokens, seq_len=5)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA5UoQHttS-u",
    "outputId": "12ba08f9-1f0e-4469-960c-750084dc6e18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordLSTM(\n",
       "  (emb_layer): Embedding(4152, 200)\n",
       "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=4152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=200)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y99lpbHNtS-v",
    "outputId": "f0b60900-cf62-4280-ec11-2a275372d9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/3925, Train Loss: 8.338584899902344\n",
      "Epoch: 1/5, Step: 800/3925, Train Loss: 6.1500468254089355\n",
      "Epoch: 1/5, Step: 1600/3925, Train Loss: 6.0997419357299805\n",
      "Epoch: 1/5, Step: 2400/3925, Train Loss: 6.155903339385986\n",
      "Epoch: 1/5, Step: 3200/3925, Train Loss: 5.876415252685547\n",
      "Epoch: 1/5, Train Loss: 6.08282847252621\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/3925, Train Loss: 5.812653541564941\n",
      "Epoch: 2/5, Step: 800/3925, Train Loss: 5.874948024749756\n",
      "Epoch: 2/5, Step: 1600/3925, Train Loss: 5.4947829246521\n",
      "Epoch: 2/5, Step: 2400/3925, Train Loss: 5.484261512756348\n",
      "Epoch: 2/5, Step: 3200/3925, Train Loss: 5.39902925491333\n",
      "Epoch: 2/5, Train Loss: 5.594286084266225\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/3925, Train Loss: 5.508958339691162\n",
      "Epoch: 3/5, Step: 800/3925, Train Loss: 5.37017297744751\n",
      "Epoch: 3/5, Step: 1600/3925, Train Loss: 5.195843696594238\n",
      "Epoch: 3/5, Step: 2400/3925, Train Loss: 5.228837013244629\n",
      "Epoch: 3/5, Step: 3200/3925, Train Loss: 5.063619136810303\n",
      "Epoch: 3/5, Train Loss: 5.315553171680231\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/3925, Train Loss: 5.125120162963867\n",
      "Epoch: 4/5, Step: 800/3925, Train Loss: 5.428244113922119\n",
      "Epoch: 4/5, Step: 1600/3925, Train Loss: 5.200814723968506\n",
      "Epoch: 4/5, Step: 2400/3925, Train Loss: 5.243772983551025\n",
      "Epoch: 4/5, Step: 3200/3925, Train Loss: 5.350257396697998\n",
      "Epoch: 4/5, Train Loss: 5.106992859810021\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/3925, Train Loss: 4.675249099731445\n",
      "Epoch: 5/5, Step: 800/3925, Train Loss: 4.441941738128662\n",
      "Epoch: 5/5, Step: 1600/3925, Train Loss: 5.003734111785889\n",
      "Epoch: 5/5, Step: 2400/3925, Train Loss: 5.133343696594238\n",
      "Epoch: 5/5, Step: 3200/3925, Train Loss: 4.70917272567749\n",
      "Epoch: 5/5, Train Loss: 4.960831437323503\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0VV0UQwDweb0"
   },
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    value, idx = torch.topk(logits, k)\n",
    "    logits[logits < value[:, [-1]]] = -float('Inf')\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KbWv8NFrqKtI"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "# predict next token\n",
    "def predict(word, hidden, top_k, sample):\n",
    "         \n",
    "    # tensor inputs\n",
    "    word = word if word in word2idx else '<unk>'\n",
    "    x = np.array([[word2idx[word]]])\n",
    "    inputs = torch.tensor(x).to(device)\n",
    "    hidden = tuple([i.data for i in hidden])\n",
    "\n",
    "    # get the output of the model\n",
    "    logits, hidden = model(inputs, hidden)\n",
    "\n",
    "    # get the token probabilities\n",
    "    if top_k is not None:\n",
    "        logits = top_k_logits(logits, top_k)\n",
    "    # apply softmax to convert to probabilities\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    # sample from the distribution or take the most likely\n",
    "    if sample:\n",
    "        idx = torch.multinomial(probs, num_samples=1)\n",
    "    else:\n",
    "        value, idx = torch.topk(probs, k=1, dim=-1)\n",
    "    # return the encoded value of the predicted word and the hidden state\n",
    "    return idx2word[idx.item()], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ocpiaPZStS-v"
   },
   "outputs": [],
   "source": [
    "# function to generate text\n",
    "def sample(max_step=100, context='<s>', top_k=None, sample=True):\n",
    "        \n",
    "    # push to GPU\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1)\n",
    "    tokens = context.split()\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(max_step):\n",
    "        token, hidden = predict(tokens[-1], hidden, top_k, sample)\n",
    "        tokens.append(token)\n",
    "        if token == '<\\s>':\n",
    "            return ' '.join(tokens)\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VqjdXiRNqtnc"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JpghHgNu5leX"
   },
   "outputs": [],
   "source": [
    "def get_prob(word,hidden,target):\n",
    "    word = word if word in word2idx else '<unk>'\n",
    "    target = target if target in word2idx else '<unk>'\n",
    "    x = np.array([[word2idx[word]]])\n",
    "    y = np.array([[word2idx[target]]])\n",
    "    inputs = torch.tensor(x).to(device)\n",
    "    hidden = tuple([i.data for i in hidden])\n",
    "\n",
    "    # get the output of the model\n",
    "    logits, hidden = model(inputs, hidden)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    prob = probs[0,y].item()\n",
    "    return prob, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I5DfI8665lgT"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_perplex(model, test_tokens):\n",
    "    all_perplex = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for tokens in test_tokens:\n",
    "        sent_perplex = 0\n",
    "        hidden = model.init_hidden(1)\n",
    "        for i in range(len(tokens)-1):\n",
    "            prob, hidden = get_prob(tokens[i],hidden,tokens[i+1])\n",
    "            sent_perplex += -np.log(prob)\n",
    "        all_perplex.append(sent_perplex/len(tokens))\n",
    "    print(\"Test perplexity: {}\".format(np.exp(np.mean(all_perplex))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QU_R9pjlCN-h"
   },
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "with open('test_1.txt') as f:\n",
    "    for line in f:\n",
    "        test_tokens.append(line.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByFpc1zo5lim",
    "outputId": "520558e8-bc93-40b1-9e52-5bad2be43ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 134.93943483325958\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb6B20IHByvI"
   },
   "source": [
    "## Sequence length: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JRwOO1gLmhh7"
   },
   "outputs": [],
   "source": [
    "train_set_2 = SeqDataset(text_tokens, seq_len=25)\n",
    "train_loader_2 = DataLoader(train_set_2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ke4JRNK9tS-w",
    "outputId": "fa62589e-d691-480e-cd5e-31048093ed81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordLSTM(\n",
       "  (emb_layer): Embedding(4152, 200)\n",
       "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=4152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WordLSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EnM7khetS-x",
    "outputId": "b1baae55-1a95-466c-a301-b68c8bdf717d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1467, Train Loss: 8.327515602111816\n",
      "Epoch: 1/5, Step: 800/1467, Train Loss: 6.036366939544678\n",
      "Epoch: 1/5, Train Loss: 6.02771867857389\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1467, Train Loss: 5.889590740203857\n",
      "Epoch: 2/5, Step: 800/1467, Train Loss: 5.848283767700195\n",
      "Epoch: 2/5, Train Loss: 5.862490297420218\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1467, Train Loss: 5.7718892097473145\n",
      "Epoch: 3/5, Step: 800/1467, Train Loss: 5.745514392852783\n",
      "Epoch: 3/5, Train Loss: 5.748726030556458\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1467, Train Loss: 5.903743743896484\n",
      "Epoch: 4/5, Step: 800/1467, Train Loss: 5.521963119506836\n",
      "Epoch: 4/5, Train Loss: 5.47387253742439\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1467, Train Loss: 5.176084518432617\n",
      "Epoch: 5/5, Step: 800/1467, Train Loss: 5.152724742889404\n",
      "Epoch: 5/5, Train Loss: 5.066474747479003\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader_2, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DHqN8aVjtS-x"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_2.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Bzv2EVd2cmG",
    "outputId": "67ce8448-d735-42aa-b534-01957e13f74e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 144.19671284051736\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GdwkcimB6fe"
   },
   "source": [
    "## better model on test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8C2uQb03EaT5"
   },
   "outputs": [],
   "source": [
    "test_tokens_2 = []\n",
    "with open('test_2.txt') as f:\n",
    "    for line in f:\n",
    "        test_tokens_2.append(line.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jv1UlRw3h9Kf",
    "outputId": "ae6a713b-cae7-4de0-a7a5-c2a6ea8b32ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_best.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAWTOrN4EaWW",
    "outputId": "ee8a7e1e-3aec-4518-a9b0-ecf1dce3985f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 228.35428312845553\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUWi9yuI2Wxs"
   },
   "source": [
    "## Glove vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "idnxo3rsEaen"
   },
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Vy2Cl66vEagr"
   },
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "Glove = torchtext.vocab.GloVe(name='6B', dim=embed_dim, cache='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NmNDflxPr9L8"
   },
   "outputs": [],
   "source": [
    "def get_pretrained_embed(word2idx):\n",
    "    pretrained_embed = torch.zeros((len(word2idx), embed_dim))\n",
    "\n",
    "    for i, word in enumerate(word2idx.keys()):\n",
    "        if word in Glove.stoi:\n",
    "            pretrained_embed[i] = Glove[word]\n",
    "        else:\n",
    "            pretrained_embed[i] = np.random.normal(embed_dim)\n",
    "    print(\"pretrained embedding size: {}\".format(pretrained_embed.shape))\n",
    "    return pretrained_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhkgRT8Pr9L8",
    "outputId": "9d68b22b-7ef8-48c6-d6f8-632d8ca97959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained embedding size: torch.Size([4152, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embed = get_pretrained_embed(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMvCqjnDr9L8",
    "outputId": "5261d715-4486-43ba-ced7-326f77ac9f99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordLSTM(\n",
       "  (emb_layer): Embedding(4152, 100)\n",
       "  (lstm): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=4152, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RT6PTpRmr9L9"
   },
   "outputs": [],
   "source": [
    "# load pretrain_embed\n",
    "model.emb_layer.weight.data.copy_(pretrained_embed)\n",
    "model.emb_layer.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMnd-2wlr9L9",
    "outputId": "b9c02463-e42c-4df5-9d33-3b4ff59f030e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/3925, Train Loss: 8.325315475463867\n",
      "Epoch: 1/5, Step: 800/3925, Train Loss: 6.068885326385498\n",
      "Epoch: 1/5, Step: 1600/3925, Train Loss: 5.694124698638916\n",
      "Epoch: 1/5, Step: 2400/3925, Train Loss: 6.004619121551514\n",
      "Epoch: 1/5, Step: 3200/3925, Train Loss: 6.01119327545166\n",
      "Epoch: 1/5, Train Loss: 6.095573914521819\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/3925, Train Loss: 6.211051940917969\n",
      "Epoch: 2/5, Step: 800/3925, Train Loss: 5.377532958984375\n",
      "Epoch: 2/5, Step: 1600/3925, Train Loss: 5.4888153076171875\n",
      "Epoch: 2/5, Step: 2400/3925, Train Loss: 5.583943843841553\n",
      "Epoch: 2/5, Step: 3200/3925, Train Loss: 5.578301429748535\n",
      "Epoch: 2/5, Train Loss: 5.670285832714883\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/3925, Train Loss: 4.9225053787231445\n",
      "Epoch: 3/5, Step: 800/3925, Train Loss: 5.4769415855407715\n",
      "Epoch: 3/5, Step: 1600/3925, Train Loss: 5.49036979675293\n",
      "Epoch: 3/5, Step: 2400/3925, Train Loss: 5.086743354797363\n",
      "Epoch: 3/5, Step: 3200/3925, Train Loss: 5.284717559814453\n",
      "Epoch: 3/5, Train Loss: 5.3284924315191375\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/3925, Train Loss: 5.4409613609313965\n",
      "Epoch: 4/5, Step: 800/3925, Train Loss: 5.375649929046631\n",
      "Epoch: 4/5, Step: 1600/3925, Train Loss: 5.250715255737305\n",
      "Epoch: 4/5, Step: 2400/3925, Train Loss: 5.408073425292969\n",
      "Epoch: 4/5, Step: 3200/3925, Train Loss: 5.05704402923584\n",
      "Epoch: 4/5, Train Loss: 5.1538478393311715\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/3925, Train Loss: 4.919820308685303\n",
      "Epoch: 5/5, Step: 800/3925, Train Loss: 4.684164524078369\n",
      "Epoch: 5/5, Step: 1600/3925, Train Loss: 5.0922722816467285\n",
      "Epoch: 5/5, Step: 2400/3925, Train Loss: 5.371917247772217\n",
      "Epoch: 5/5, Step: 3200/3925, Train Loss: 4.976413726806641\n",
      "Epoch: 5/5, Train Loss: 5.023361100239359\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "q0a9mYdDGf0w"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_3.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-af4rAQr9L9",
    "outputId": "eef748bd-cde2-41c5-b4b8-70aff6b026da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 128.33346522969657\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PibvIeQ2QH6"
   },
   "source": [
    "## Tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "N0LP1bNk0Hi9"
   },
   "outputs": [],
   "source": [
    "tweet_text = []\n",
    "with open('tweet.txt') as f:\n",
    "    for line in f:\n",
    "        tweet_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9qSeq2Qa2tEY"
   },
   "outputs": [],
   "source": [
    "text_tokens = [text.split() for text in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EqyP1uZH2tGm",
    "outputId": "3e16eb1f-3ef0-4a42-f99f-81e9fa466184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab number: 3997\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = get_dict(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZVv6joNBg0F"
   },
   "source": [
    "## Sequence length: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QqJ5piMC22tO"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set_3 = SeqDataset(text_tokens, seq_len=5)\n",
    "train_loader_3 = DataLoader(train_set_3, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "rErl5Ipa22vn"
   },
   "outputs": [],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=200)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjBtuu2k22xl",
    "outputId": "9af388b4-46d6-4cb0-b2b3-8c891e031668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/2465, Train Loss: 8.283422470092773\n",
      "Epoch: 1/5, Step: 800/2465, Train Loss: 6.224873065948486\n",
      "Epoch: 1/5, Step: 1600/2465, Train Loss: 6.236417770385742\n",
      "Epoch: 1/5, Step: 2400/2465, Train Loss: 5.787410736083984\n",
      "Epoch: 1/5, Train Loss: 6.137932942218278\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/2465, Train Loss: 6.110302925109863\n",
      "Epoch: 2/5, Step: 800/2465, Train Loss: 6.350065231323242\n",
      "Epoch: 2/5, Step: 1600/2465, Train Loss: 6.189631462097168\n",
      "Epoch: 2/5, Step: 2400/2465, Train Loss: 5.770730495452881\n",
      "Epoch: 2/5, Train Loss: 5.921329023001402\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/2465, Train Loss: 5.921454906463623\n",
      "Epoch: 3/5, Step: 800/2465, Train Loss: 5.723166465759277\n",
      "Epoch: 3/5, Step: 1600/2465, Train Loss: 5.641420841217041\n",
      "Epoch: 3/5, Step: 2400/2465, Train Loss: 5.6212358474731445\n",
      "Epoch: 3/5, Train Loss: 5.695617106284863\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/2465, Train Loss: 5.821914196014404\n",
      "Epoch: 4/5, Step: 800/2465, Train Loss: 5.648041725158691\n",
      "Epoch: 4/5, Step: 1600/2465, Train Loss: 5.668653964996338\n",
      "Epoch: 4/5, Step: 2400/2465, Train Loss: 5.687868118286133\n",
      "Epoch: 4/5, Train Loss: 5.508335206378063\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/2465, Train Loss: 5.310031890869141\n",
      "Epoch: 5/5, Step: 800/2465, Train Loss: 5.230783462524414\n",
      "Epoch: 5/5, Step: 1600/2465, Train Loss: 5.671728134155273\n",
      "Epoch: 5/5, Step: 2400/2465, Train Loss: 5.689102649688721\n",
      "Epoch: 5/5, Train Loss: 5.379410546014565\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader_3, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3huYQK9fARNv"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_4.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5tYeBfEDQWd",
    "outputId": "e8131706-02c4-474d-a6d0-0d3eb2adf121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 114.09393206329511\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0an9jL5AwqF"
   },
   "source": [
    "## Sequence length: 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "DmVqTnWPAY8u"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set_4 = SeqDataset(text_tokens, seq_len=15)\n",
    "train_loader_4 = DataLoader(train_set_4, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "cnWucWxBAY-y"
   },
   "outputs": [],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=200)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4A7hbPeCAZCT",
    "outputId": "5a7d0222-d492-4f49-f814-5272dd1245e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1061, Train Loss: 8.298203468322754\n",
      "Epoch: 1/5, Step: 800/1061, Train Loss: 5.970295429229736\n",
      "Epoch: 1/5, Train Loss: 6.135001772198331\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1061, Train Loss: 5.942286014556885\n",
      "Epoch: 2/5, Step: 800/1061, Train Loss: 5.8520073890686035\n",
      "Epoch: 2/5, Train Loss: 5.903343921557111\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1061, Train Loss: 5.9632062911987305\n",
      "Epoch: 3/5, Step: 800/1061, Train Loss: 5.996168613433838\n",
      "Epoch: 3/5, Train Loss: 5.84365752010723\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1061, Train Loss: 5.6815385818481445\n",
      "Epoch: 4/5, Step: 800/1061, Train Loss: 5.9780755043029785\n",
      "Epoch: 4/5, Train Loss: 5.793503226478857\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1061, Train Loss: 5.68289041519165\n",
      "Epoch: 5/5, Step: 800/1061, Train Loss: 5.526974678039551\n",
      "Epoch: 5/5, Train Loss: 5.701874151868038\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader_4, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "kM32SgywBb5_"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_5.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLRlrGI0BcDH",
    "outputId": "6f139145-11d3-42a8-80bc-2c2fe6655f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 127.75258888220837\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE9lsduDD6Af"
   },
   "source": [
    "## better model on test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou7y2-TVovVX",
    "outputId": "d2781e08-ca19-4724-d7a6-8789275aad3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_best.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOqcNfdjBcFe",
    "outputId": "cf556344-5724-4a72-ec7e-db6eadcedcdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 145.24113031324816\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrKZpUe_EQSJ"
   },
   "source": [
    "## Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhKMJ8ZrAZD3",
    "outputId": "7f0961e7-3f69-4b14-e07c-4ac8efe78547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained embedding size: torch.Size([3997, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embed = get_pretrained_embed(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Mvx3Oum_FwY6"
   },
   "outputs": [],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "cuyGK5AZFwbC"
   },
   "outputs": [],
   "source": [
    "# load pretrain_embed\n",
    "model.emb_layer.weight.data.copy_(pretrained_embed)\n",
    "model.emb_layer.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EfJIW3VGuuC",
    "outputId": "3ad91494-c26e-4f8e-f681-e39723d4cd47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/2465, Train Loss: 8.285900115966797\n",
      "Epoch: 1/5, Step: 800/2465, Train Loss: 5.965482234954834\n",
      "Epoch: 1/5, Step: 1600/2465, Train Loss: 6.151297569274902\n",
      "Epoch: 1/5, Step: 2400/2465, Train Loss: 5.83143949508667\n",
      "Epoch: 1/5, Train Loss: 6.108056863664856\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/2465, Train Loss: 5.952112674713135\n",
      "Epoch: 2/5, Step: 800/2465, Train Loss: 5.813508987426758\n",
      "Epoch: 2/5, Step: 1600/2465, Train Loss: 6.064155578613281\n",
      "Epoch: 2/5, Step: 2400/2465, Train Loss: 5.619847774505615\n",
      "Epoch: 2/5, Train Loss: 5.928172902693372\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/2465, Train Loss: 5.819441318511963\n",
      "Epoch: 3/5, Step: 800/2465, Train Loss: 5.717911720275879\n",
      "Epoch: 3/5, Step: 1600/2465, Train Loss: 5.784095764160156\n",
      "Epoch: 3/5, Step: 2400/2465, Train Loss: 5.605437278747559\n",
      "Epoch: 3/5, Train Loss: 5.720361549617311\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/2465, Train Loss: 5.382509708404541\n",
      "Epoch: 4/5, Step: 800/2465, Train Loss: 5.3306779861450195\n",
      "Epoch: 4/5, Step: 1600/2465, Train Loss: 5.855619430541992\n",
      "Epoch: 4/5, Step: 2400/2465, Train Loss: 5.3145976066589355\n",
      "Epoch: 4/5, Train Loss: 5.549448057023797\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/2465, Train Loss: 5.157700538635254\n",
      "Epoch: 5/5, Step: 800/2465, Train Loss: 5.410523891448975\n",
      "Epoch: 5/5, Step: 1600/2465, Train Loss: 5.607982635498047\n",
      "Epoch: 5/5, Step: 2400/2465, Train Loss: 5.037917613983154\n",
      "Epoch: 5/5, Train Loss: 5.405173481405386\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader_3, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "c5Z7G5XoF28i"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_6.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiyQPdtSF5Wx",
    "outputId": "9683060e-d3ed-4b0d-d56b-d4fdf2794d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 118.29567983443539\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPc4x3rDG_9Y"
   },
   "source": [
    "## GloveTwitter vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "uekKuP1dF5cw"
   },
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "Glove = torchtext.vocab.GloVe(name='twitter.27B', dim=embed_dim, cache='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "UbYWkni0F5gU"
   },
   "outputs": [],
   "source": [
    "model = WordLSTM(vocab_size=len(word2idx), embed_dim=100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9T2KZUvJrVO",
    "outputId": "4f7faaa8-d909-4ac2-c631-26c6410bfaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/2465, Train Loss: 8.287731170654297\n",
      "Epoch: 1/5, Step: 800/2465, Train Loss: 5.763376712799072\n",
      "Epoch: 1/5, Step: 1600/2465, Train Loss: 5.944653511047363\n",
      "Epoch: 1/5, Step: 2400/2465, Train Loss: 6.010117053985596\n",
      "Epoch: 1/5, Train Loss: 6.140636523210011\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/2465, Train Loss: 5.856949329376221\n",
      "Epoch: 2/5, Step: 800/2465, Train Loss: 5.867694854736328\n",
      "Epoch: 2/5, Step: 1600/2465, Train Loss: 5.806730270385742\n",
      "Epoch: 2/5, Step: 2400/2465, Train Loss: 5.4784369468688965\n",
      "Epoch: 2/5, Train Loss: 5.923018555515436\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/2465, Train Loss: 5.412802696228027\n",
      "Epoch: 3/5, Step: 800/2465, Train Loss: 5.90138053894043\n",
      "Epoch: 3/5, Step: 1600/2465, Train Loss: 5.712285041809082\n",
      "Epoch: 3/5, Step: 2400/2465, Train Loss: 5.912449359893799\n",
      "Epoch: 3/5, Train Loss: 5.734100012556777\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/2465, Train Loss: 5.593371868133545\n",
      "Epoch: 4/5, Step: 800/2465, Train Loss: 5.679388999938965\n",
      "Epoch: 4/5, Step: 1600/2465, Train Loss: 5.576924800872803\n",
      "Epoch: 4/5, Step: 2400/2465, Train Loss: 5.567097187042236\n",
      "Epoch: 4/5, Train Loss: 5.586471145196571\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/2465, Train Loss: 5.529299259185791\n",
      "Epoch: 5/5, Step: 800/2465, Train Loss: 5.234795570373535\n",
      "Epoch: 5/5, Step: 1600/2465, Train Loss: 5.570270538330078\n",
      "Epoch: 5/5, Step: 2400/2465, Train Loss: 5.697935104370117\n",
      "Epoch: 5/5, Train Loss: 5.467735006359479\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(dataloader=train_loader_3, num_epochs=5, clip=1, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "w1WxYY6UJrXa"
   },
   "outputs": [],
   "source": [
    "generate_sent = [] \n",
    "for i in range(10):\n",
    "    sent = sample(max_step=30,context='<s>',top_k=20,sample=True)\n",
    "    generate_sent.append(sent)\n",
    "with open('generate_text_7.txt','w') as f:\n",
    "    for sent in generate_sent:\n",
    "        f.write(\"{}\\n\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKEFNBvPJ1Ox",
    "outputId": "d5166dff-f965-4b90-9f86-c647658d5119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity: 121.52823262088273\n"
     ]
    }
   ],
   "source": [
    "compute_perplex(model, test_tokens_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pkyD_d4Khf8"
   },
   "source": [
    "# LSTM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "Qji5IHt3RY-J"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "BBBEhPdmKgvb"
   },
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "train_labels = []\n",
    "with open('sentiment-train.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        label, text = line\n",
    "        train_sentences.append(text)\n",
    "        train_labels.append(float(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "IgMcTp84Kgxe"
   },
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "test_labels = []\n",
    "with open('sentiment-test.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        label, text = line\n",
    "        test_sentences.append(text)\n",
    "        test_labels.append(float(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "1JknklDneWSB"
   },
   "outputs": [],
   "source": [
    "# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\n",
    "def pad_input(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for i, review in enumerate(sentences):\n",
    "        if len(review) > 0:\n",
    "            features[i, :len(review)] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "9EryfWhNeC11"
   },
   "outputs": [],
   "source": [
    "def process_data(train_sentences, train_labels, test_sentences, test_labels, padding_length=30):\n",
    "    for i in range(len(train_sentences)):\n",
    "        train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
    "    for i in range(len(test_sentences)):\n",
    "        test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
    "\n",
    "    # Modify URLs to <url>\n",
    "    for i in range(len(train_sentences)):\n",
    "        if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "            train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i]) \n",
    "    for i in range(len(test_sentences)):\n",
    "        if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "            test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])\n",
    "\n",
    "    vocab = Counter() #Dictionary that will map a word to the number of times it appeared in all the training sentences\n",
    "    train_tokens = []\n",
    "    for i, sentence in enumerate(train_sentences):\n",
    "        #The sentences will be stored as a list of words/tokens\n",
    "        tokens = []\n",
    "        for word in nltk.word_tokenize(sentence): #Tokenizing the words\n",
    "            vocab.update([word.lower()]) #Converting all the words to lower case\n",
    "            tokens.append(word)\n",
    "        train_tokens.append(tokens)\n",
    "        if i%(len(train_sentences)/10) == 0:\n",
    "            print(str((i*100)/len(train_sentences)) + \"% done\")\n",
    "    print(\"100% done\")\n",
    "\n",
    "    vocab = {k:v for k,v in vocab.items() if v>1}\n",
    "    # Sorting the words according to the number of appearances, with the most common word being first\n",
    "    vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "    # Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "    vocab = ['<pad>','<unk>'] + vocab\n",
    "    # Dictionaries to store the word to index mappings and vice versa\n",
    "    word2idx = {o:i for i,o in enumerate(vocab)}\n",
    "    idx2word = {i:o for i,o in enumerate(vocab)}\n",
    "    print(\"vocab number: {}\".format(len(vocab)))\n",
    "\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i, tokens in enumerate(train_tokens):\n",
    "        # Looking up the mapping dictionary and assigning the index to the respective words\n",
    "        train_idx.append([word2idx[word] if word in word2idx else word2idx['<unk>'] for word in tokens])\n",
    "\n",
    "    for i, sentence in enumerate(test_sentences):\n",
    "        # For test sentences, we have to tokenize the sentences as well\n",
    "        test_idx.append([word2idx[word.lower()] if word.lower() in word2idx else word2idx['<unk>'] for word in nltk.word_tokenize(sentence)])\n",
    "    seq_len = padding_length #The length that the sentences will be padded/shortened to\n",
    "    train_idx = pad_input(train_idx, seq_len)\n",
    "    test_idx = pad_input(test_idx, seq_len)\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    train_data = TensorDataset(torch.from_numpy(train_idx), torch.from_numpy(train_labels))\n",
    "    test_data = TensorDataset(torch.from_numpy(test_idx), torch.from_numpy(test_labels))\n",
    "\n",
    "    return word2idx, idx2word, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQPuzxAQe1pO",
    "outputId": "cae1b06c-cd2a-4d5a-c314-16c09d685aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      "10.0% done\n",
      "20.0% done\n",
      "30.0% done\n",
      "40.0% done\n",
      "50.0% done\n",
      "60.0% done\n",
      "70.0% done\n",
      "80.0% done\n",
      "90.0% done\n",
      "100% done\n",
      "vocab number: 19959\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word, train_data, test_data = process_data(train_sentences, train_labels, test_sentences, test_labels, padding_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "DmD_ImX2dmMo"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "8pjAHtLNOtcn"
   },
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=False):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if use_model.lower() == 'lstm':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=0.5, batch_first=True, bidirectional=bidirectional)\n",
    "        if use_model.lower() == 'gru':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=0.5, batch_first=True, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        out, hidden = self.rnn(embeds, hidden)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "86FqsJMq4ES6"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs=10, train_loader=None, valid_loader=None, clip=5, interval=300, valid_acc_all=[]):\n",
    "\n",
    "    loss_min = 99\n",
    "    max_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # hidden = tuple([e.data for e in hidden])\n",
    "            inputs, labels = inputs.long().to(device), labels.to(device)\n",
    "\n",
    "            output, hidden = model(inputs, None)\n",
    "            loss = loss_fn(output.squeeze(-1), labels.float())\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % interval == 0:\n",
    "                print(\"Epoch: {}/{}, Step: {}/{}, Train Loss: {}\".format(epoch+1, num_epochs, i, len(train_loader), loss))\n",
    "        epoch_loss = np.mean(train_loss)\n",
    "        print(\"Epoch: {}/{}, Train Loss: {}\".format(epoch+1, num_epochs, epoch_loss))\n",
    "\n",
    "        if valid_loader != None:\n",
    "            model.eval()\n",
    "            valid_loss = []\n",
    "            num_correct = 0\n",
    "            for i, (inputs, labels) in enumerate(valid_loader):\n",
    "                # val_hidden = tuple([each.data for each in val_h])\n",
    "                inputs, labels = inputs.long().to(device), labels.to(device)\n",
    "                output, hidden = model(inputs, None)\n",
    "                loss = loss_fn(output.squeeze(-1), labels.float())\n",
    "                valid_loss.append(loss.item())\n",
    "                pred = torch.round(output.squeeze(-1))\n",
    "                correct = pred.eq(labels.float()).cpu().numpy()\n",
    "                num_correct += np.sum(correct)\n",
    "\n",
    "            print(\"Epoch: {}/{}, Valid Loss: {}\".format(epoch+1, num_epochs, np.mean(valid_loss)))\n",
    "            valid_acc = num_correct/len(test_loader.dataset)\n",
    "            max_acc = max(max_acc, valid_acc)\n",
    "            print(\"Epoch: {}/{}, Valid accuracy: {:.3f}%\".format(epoch+1, num_epochs, valid_acc*100))\n",
    "\n",
    "        if epoch_loss < loss_min:\n",
    "            torch.save(model.state_dict(), 'bestmodel_sentiment.pt')\n",
    "            print('Model saved successfully')\n",
    "            loss_min = epoch_loss\n",
    "        print()\n",
    "    if valid_loader != None:\n",
    "        valid_acc_all.append(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "WCcPVms94b1q"
   },
   "outputs": [],
   "source": [
    "def test(test_loader):\n",
    "    test_loss = []\n",
    "    num_correct = 0\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        # hidden = tuple([each.data for each in hidden])\n",
    "        inputs, labels = inputs.long().to(device), labels.to(device)\n",
    "\n",
    "        output, hidden = model(inputs, None)\n",
    "        loss = loss_fn(output.squeeze(-1), labels.float())\n",
    "        test_loss.append(loss.item())\n",
    "        pred = torch.round(output.squeeze(-1))\n",
    "        \n",
    "        correct = pred.eq(labels.float()).cpu().numpy()\n",
    "        num_correct += np.sum(correct)\n",
    "            \n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_loss)))\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTXpPpPvIPba",
    "outputId": "64a9be91-fcb0-4b5d-e5ac-074d9f3ed156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 400)\n",
       "  (rnn): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkc593gPH5N8",
    "outputId": "ad2138ac-77a8-4c27-fc38-6152a67c50df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1875, Train Loss: 0.6896765232086182\n",
      "Epoch: 1/5, Step: 500/1875, Train Loss: 0.6008710861206055\n",
      "Epoch: 1/5, Step: 1000/1875, Train Loss: 0.6363990306854248\n",
      "Epoch: 1/5, Step: 1500/1875, Train Loss: 0.6959047317504883\n",
      "Epoch: 1/5, Train Loss: 0.5760922355969746\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1875, Train Loss: 0.5280606746673584\n",
      "Epoch: 2/5, Step: 500/1875, Train Loss: 0.4512268006801605\n",
      "Epoch: 2/5, Step: 1000/1875, Train Loss: 0.4189934730529785\n",
      "Epoch: 2/5, Step: 1500/1875, Train Loss: 0.5200663805007935\n",
      "Epoch: 2/5, Train Loss: 0.4904069847583771\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1875, Train Loss: 0.5496572256088257\n",
      "Epoch: 3/5, Step: 500/1875, Train Loss: 0.5087374448776245\n",
      "Epoch: 3/5, Step: 1000/1875, Train Loss: 0.5441999435424805\n",
      "Epoch: 3/5, Step: 1500/1875, Train Loss: 0.496160626411438\n",
      "Epoch: 3/5, Train Loss: 0.4626253471215566\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1875, Train Loss: 0.5688390731811523\n",
      "Epoch: 4/5, Step: 500/1875, Train Loss: 0.5063639879226685\n",
      "Epoch: 4/5, Step: 1000/1875, Train Loss: 0.47099748253822327\n",
      "Epoch: 4/5, Step: 1500/1875, Train Loss: 0.3713859021663666\n",
      "Epoch: 4/5, Train Loss: 0.4559985447804133\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1875, Train Loss: 0.46879643201828003\n",
      "Epoch: 5/5, Step: 500/1875, Train Loss: 0.3368658721446991\n",
      "Epoch: 5/5, Step: 1000/1875, Train Loss: 0.29068559408187866\n",
      "Epoch: 5/5, Step: 1500/1875, Train Loss: 0.37192147970199585\n",
      "Epoch: 5/5, Train Loss: 0.44815788226127623\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=5, train_loader=train_loader, valid_loader=None, clip=5, interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urOW-UiWD_lG",
    "outputId": "af0fa5f5-5c8e-4b77-b9b8-83a53e02e904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.517\n",
      "Test accuracy: 75.209%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Fq3jGsaHMm6"
   },
   "source": [
    "## Use GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Bcf6RPiEAec",
    "outputId": "c86a0b68-2980-40ab-8909-4a7597c408b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 400)\n",
       "  (rnn): GRU(400, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='gru', bidirectional=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHlnFIGWFJd9",
    "outputId": "e5ee7394-0a94-44ba-db12-67c5a3bb53ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1875, Train Loss: 0.7007261514663696\n",
      "Epoch: 1/5, Step: 500/1875, Train Loss: 0.706928551197052\n",
      "Epoch: 1/5, Step: 1000/1875, Train Loss: 0.5427626967430115\n",
      "Epoch: 1/5, Step: 1500/1875, Train Loss: 0.6162347793579102\n",
      "Epoch: 1/5, Train Loss: 0.6264342344919841\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1875, Train Loss: 0.692589521408081\n",
      "Epoch: 2/5, Step: 500/1875, Train Loss: 0.5782080888748169\n",
      "Epoch: 2/5, Step: 1000/1875, Train Loss: 0.652542233467102\n",
      "Epoch: 2/5, Step: 1500/1875, Train Loss: 0.6577836871147156\n",
      "Epoch: 2/5, Train Loss: 0.6053669723510742\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1875, Train Loss: 0.6928296089172363\n",
      "Epoch: 3/5, Step: 500/1875, Train Loss: 0.40084144473075867\n",
      "Epoch: 3/5, Step: 1000/1875, Train Loss: 0.509823203086853\n",
      "Epoch: 3/5, Step: 1500/1875, Train Loss: 0.8983087539672852\n",
      "Epoch: 3/5, Train Loss: 0.6368058365186056\n",
      "\n",
      "Epoch: 4/5, Step: 0/1875, Train Loss: 0.44613561034202576\n",
      "Epoch: 4/5, Step: 500/1875, Train Loss: 0.5744693279266357\n",
      "Epoch: 4/5, Step: 1000/1875, Train Loss: 0.4197928309440613\n",
      "Epoch: 4/5, Step: 1500/1875, Train Loss: 0.7856220006942749\n",
      "Epoch: 4/5, Train Loss: 0.6342199303309123\n",
      "\n",
      "Epoch: 5/5, Step: 0/1875, Train Loss: 0.8398085832595825\n",
      "Epoch: 5/5, Step: 500/1875, Train Loss: 0.568242609500885\n",
      "Epoch: 5/5, Step: 1000/1875, Train Loss: 0.5737144947052002\n",
      "Epoch: 5/5, Step: 1500/1875, Train Loss: 0.8769269585609436\n",
      "Epoch: 5/5, Train Loss: 0.638041253042221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=5, train_loader=train_loader, valid_loader=None, clip=5, interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHYbfodTJl-X",
    "outputId": "86ac36ed-1f03-468e-b123-6d48f09139f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.678\n",
      "Test accuracy: 61.838%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuYuOqxdLH1e"
   },
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9M8gnr8JmCi",
    "outputId": "81aed116-3642-4420-def6-7400b983d00d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 400)\n",
       "  (rnn): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0baWFH_GJmEx",
    "outputId": "0efd30ef-0f6e-4626-be14-15222f756c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1875, Train Loss: 0.6933279633522034\n",
      "Epoch: 1/5, Step: 800/1875, Train Loss: 0.556958794593811\n",
      "Epoch: 1/5, Step: 1600/1875, Train Loss: 0.6091010570526123\n",
      "Epoch: 1/5, Train Loss: 0.6177551045735677\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1875, Train Loss: 0.5861363410949707\n",
      "Epoch: 2/5, Step: 800/1875, Train Loss: 0.3751044273376465\n",
      "Epoch: 2/5, Step: 1600/1875, Train Loss: 0.5037902593612671\n",
      "Epoch: 2/5, Train Loss: 0.5140378169616063\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1875, Train Loss: 0.6879075765609741\n",
      "Epoch: 3/5, Step: 800/1875, Train Loss: 0.2774255573749542\n",
      "Epoch: 3/5, Step: 1600/1875, Train Loss: 0.6646953821182251\n",
      "Epoch: 3/5, Train Loss: 0.48483073558012646\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1875, Train Loss: 0.30227038264274597\n",
      "Epoch: 4/5, Step: 800/1875, Train Loss: 0.5301316976547241\n",
      "Epoch: 4/5, Step: 1600/1875, Train Loss: 0.3859880864620209\n",
      "Epoch: 4/5, Train Loss: 0.46576744728088376\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1875, Train Loss: 0.43001264333724976\n",
      "Epoch: 5/5, Step: 800/1875, Train Loss: 0.434304416179657\n",
      "Epoch: 5/5, Step: 1600/1875, Train Loss: 0.6391984820365906\n",
      "Epoch: 5/5, Train Loss: 0.4529079838434855\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=5, train_loader=train_loader, valid_loader=None, clip=5, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56o6nJiCJmHD",
    "outputId": "a859e133-51f7-4996-f7b7-7233f687b5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.597\n",
      "Test accuracy: 74.652%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gD_8YBZNF23"
   },
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMlPUg60JmaP",
    "outputId": "18d65442-784b-4ddc-d4ec-abbf617195b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 400)\n",
       "  (rnn): GRU(400, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='gru', bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVMdBZthJmca",
    "outputId": "5e644fa1-f3a7-426b-e1c9-cef22f02e248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1875, Train Loss: 0.6966218948364258\n",
      "Epoch: 1/5, Step: 800/1875, Train Loss: 0.7064805030822754\n",
      "Epoch: 1/5, Step: 1600/1875, Train Loss: 0.8709197044372559\n",
      "Epoch: 1/5, Train Loss: 0.6324259975115458\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1875, Train Loss: 0.5157490968704224\n",
      "Epoch: 2/5, Step: 800/1875, Train Loss: 0.7551617622375488\n",
      "Epoch: 2/5, Step: 1600/1875, Train Loss: 0.536025881767273\n",
      "Epoch: 2/5, Train Loss: 0.6216688517649969\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1875, Train Loss: 0.682677149772644\n",
      "Epoch: 3/5, Step: 800/1875, Train Loss: 0.662162184715271\n",
      "Epoch: 3/5, Step: 1600/1875, Train Loss: 0.4738426208496094\n",
      "Epoch: 3/5, Train Loss: 0.6465229260285695\n",
      "\n",
      "Epoch: 4/5, Step: 0/1875, Train Loss: 0.778519332408905\n",
      "Epoch: 4/5, Step: 800/1875, Train Loss: 0.5623020529747009\n",
      "Epoch: 4/5, Step: 1600/1875, Train Loss: 0.49415072798728943\n",
      "Epoch: 4/5, Train Loss: 0.6205930606047313\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1875, Train Loss: 0.5738841891288757\n",
      "Epoch: 5/5, Step: 800/1875, Train Loss: 2.358701229095459\n",
      "Epoch: 5/5, Step: 1600/1875, Train Loss: 0.7390727996826172\n",
      "Epoch: 5/5, Train Loss: 0.6642020216464997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=5, train_loader=train_loader, valid_loader=None, clip=5, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsSlkCp-FJgA",
    "outputId": "38e22786-fa32-45c1-a893-7112405532eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.606\n",
      "Test accuracy: 65.738%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M6hyj-uP9KC"
   },
   "source": [
    "## GloveTwitter Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "p6qf1cpDQKr8"
   },
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "GZbPQPNSFJkS"
   },
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "Glove = torchtext.vocab.GloVe(name='twitter.27B', dim=embed_dim, cache='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvFOzwEhQcmO",
    "outputId": "e9565b85-3189-4b76-e79c-5ef8579381f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained embedding size: torch.Size([19959, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embed = get_pretrained_embed(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Shulwt4GP_9K",
    "outputId": "638e113c-1e0c-474b-f0e7-1dd488f4a20b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 100)\n",
       "  (rnn): LSTM(100, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "vrFDNnHSP__Q"
   },
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embed)\n",
    "model.embedding.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1Xlf_HtQABb",
    "outputId": "efbd4e36-136a-4344-c59d-3d64ced2c87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5, Step: 0/1875, Train Loss: 0.7052767276763916\n",
      "Epoch: 1/5, Step: 800/1875, Train Loss: 0.5163572430610657\n",
      "Epoch: 1/5, Step: 1600/1875, Train Loss: 0.5856012105941772\n",
      "Epoch: 1/5, Train Loss: 0.5601503868897756\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1875, Train Loss: 0.3237488865852356\n",
      "Epoch: 2/5, Step: 800/1875, Train Loss: 0.24358971416950226\n",
      "Epoch: 2/5, Step: 1600/1875, Train Loss: 0.7080134153366089\n",
      "Epoch: 2/5, Train Loss: 0.47873155713876087\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1875, Train Loss: 0.470812052488327\n",
      "Epoch: 3/5, Step: 800/1875, Train Loss: 0.5095195770263672\n",
      "Epoch: 3/5, Step: 1600/1875, Train Loss: 0.22125974297523499\n",
      "Epoch: 3/5, Train Loss: 0.4454321674823761\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1875, Train Loss: 0.30066439509391785\n",
      "Epoch: 4/5, Step: 800/1875, Train Loss: 0.40145742893218994\n",
      "Epoch: 4/5, Step: 1600/1875, Train Loss: 0.44392138719558716\n",
      "Epoch: 4/5, Train Loss: 0.4250964507738749\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1875, Train Loss: 0.41611620783805847\n",
      "Epoch: 5/5, Step: 800/1875, Train Loss: 0.342243492603302\n",
      "Epoch: 5/5, Step: 1600/1875, Train Loss: 0.3212713599205017\n",
      "Epoch: 5/5, Train Loss: 0.40599497849146526\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=5, train_loader=train_loader, valid_loader=None, clip=5, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5zxQpGqQADk",
    "outputId": "a5334f21-d433-462c-a735-235e5a251f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.647\n",
      "Test accuracy: 74.095%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ste9mGBzRe6y"
   },
   "source": [
    "## k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "RTdRixQZQAH0"
   },
   "outputs": [],
   "source": [
    "def random_split_data(dataset, ratio=0.8, batch_size = 32):\n",
    "    train_size = int(ratio * len(dataset))\n",
    "    valid_size = len(dataset) - train_size\n",
    "    train_data, valid_data = random_split(dataset, [train_size,valid_size])\n",
    "    print('Train samples: {}, Valid samples: {}'.format(len(train_data), len(valid_data)))\n",
    "\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F30jI3DOVBv4"
   },
   "source": [
    "### hidden size=128, embedding size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "8UvCp83JU5vZ"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOLMoZkiSuaQ",
    "outputId": "bc9354f5-7eea-442d-d19b-d515f2918df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation: 0\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6941091418266296\n",
      "Epoch: 1/5, Train Loss: 0.6502778763969739\n",
      "Epoch: 1/5, Valid Loss: 0.5388427227735519\n",
      "Epoch: 1/5, Valid accuracy: 74.930%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6555651426315308\n",
      "Epoch: 2/5, Train Loss: 0.5003530928393205\n",
      "Epoch: 2/5, Valid Loss: 0.47868334253629047\n",
      "Epoch: 2/5, Valid accuracy: 77.159%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.5481796860694885\n",
      "Epoch: 3/5, Train Loss: 0.43169332920511566\n",
      "Epoch: 3/5, Valid Loss: 0.4529117209215959\n",
      "Epoch: 3/5, Valid accuracy: 79.109%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.42115145921707153\n",
      "Epoch: 4/5, Train Loss: 0.3914153158267339\n",
      "Epoch: 4/5, Valid Loss: 0.5539292941490809\n",
      "Epoch: 4/5, Valid accuracy: 75.766%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.3646601736545563\n",
      "Epoch: 5/5, Train Loss: 0.3632792010456324\n",
      "Epoch: 5/5, Valid Loss: 0.6267219459017118\n",
      "Epoch: 5/5, Valid accuracy: 76.045%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 1\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6895227432250977\n",
      "Epoch: 1/5, Train Loss: 0.5999933827718099\n",
      "Epoch: 1/5, Valid Loss: 0.5648055399457613\n",
      "Epoch: 1/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.5600838661193848\n",
      "Epoch: 2/5, Train Loss: 0.476480624884367\n",
      "Epoch: 2/5, Valid Loss: 0.4625410462419192\n",
      "Epoch: 2/5, Valid accuracy: 78.552%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.46719714999198914\n",
      "Epoch: 3/5, Train Loss: 0.41540779479344686\n",
      "Epoch: 3/5, Valid Loss: 0.5006762022773424\n",
      "Epoch: 3/5, Valid accuracy: 78.552%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.35717159509658813\n",
      "Epoch: 4/5, Train Loss: 0.37554219147066276\n",
      "Epoch: 4/5, Valid Loss: 0.4701494152347247\n",
      "Epoch: 4/5, Valid accuracy: 77.994%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.42698922753334045\n",
      "Epoch: 5/5, Train Loss: 0.3466014755219221\n",
      "Epoch: 5/5, Valid Loss: 0.4914901927113533\n",
      "Epoch: 5/5, Valid accuracy: 78.273%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 2\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6945739984512329\n",
      "Epoch: 1/5, Train Loss: 0.6063221006393432\n",
      "Epoch: 1/5, Valid Loss: 0.5327662179867426\n",
      "Epoch: 1/5, Valid accuracy: 71.309%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6968812942504883\n",
      "Epoch: 2/5, Train Loss: 0.47784044124682745\n",
      "Epoch: 2/5, Valid Loss: 0.490402286251386\n",
      "Epoch: 2/5, Valid accuracy: 76.602%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.43811947107315063\n",
      "Epoch: 3/5, Train Loss: 0.424816620717446\n",
      "Epoch: 3/5, Valid Loss: 0.5136409476399422\n",
      "Epoch: 3/5, Valid accuracy: 77.437%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.5194324254989624\n",
      "Epoch: 4/5, Train Loss: 0.3862566966563463\n",
      "Epoch: 4/5, Valid Loss: 0.504167747994264\n",
      "Epoch: 4/5, Valid accuracy: 76.045%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.31229761242866516\n",
      "Epoch: 5/5, Train Loss: 0.3588702948192755\n",
      "Epoch: 5/5, Valid Loss: 0.5753990995387236\n",
      "Epoch: 5/5, Valid accuracy: 75.766%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 3\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6984701156616211\n",
      "Epoch: 1/5, Train Loss: 0.5888017139236132\n",
      "Epoch: 1/5, Valid Loss: 0.5299843822916349\n",
      "Epoch: 1/5, Valid accuracy: 71.866%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.4436282217502594\n",
      "Epoch: 2/5, Train Loss: 0.4691028924485048\n",
      "Epoch: 2/5, Valid Loss: 0.4810696666439374\n",
      "Epoch: 2/5, Valid accuracy: 76.323%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.31568869948387146\n",
      "Epoch: 3/5, Train Loss: 0.4116133210659027\n",
      "Epoch: 3/5, Valid Loss: 0.5069255356987318\n",
      "Epoch: 3/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.4905492961406708\n",
      "Epoch: 4/5, Train Loss: 0.3770127938389778\n",
      "Epoch: 4/5, Valid Loss: 0.5253242577115694\n",
      "Epoch: 4/5, Valid accuracy: 75.766%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.3240087628364563\n",
      "Epoch: 5/5, Train Loss: 0.3478776777187983\n",
      "Epoch: 5/5, Valid Loss: 0.5944286013642947\n",
      "Epoch: 5/5, Valid accuracy: 72.423%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 4\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.692744255065918\n",
      "Epoch: 1/5, Train Loss: 0.5993224837581317\n",
      "Epoch: 1/5, Valid Loss: 0.49159934371709824\n",
      "Epoch: 1/5, Valid accuracy: 73.816%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.39738714694976807\n",
      "Epoch: 2/5, Train Loss: 0.4736760629912217\n",
      "Epoch: 2/5, Valid Loss: 0.5095467269420624\n",
      "Epoch: 2/5, Valid accuracy: 76.323%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.27664661407470703\n",
      "Epoch: 3/5, Train Loss: 0.4148841689030329\n",
      "Epoch: 3/5, Valid Loss: 0.5049525598684946\n",
      "Epoch: 3/5, Valid accuracy: 75.766%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.4730650782585144\n",
      "Epoch: 4/5, Train Loss: 0.37318382957577706\n",
      "Epoch: 4/5, Valid Loss: 0.5102370803554853\n",
      "Epoch: 4/5, Valid accuracy: 76.045%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.3470556437969208\n",
      "Epoch: 5/5, Train Loss: 0.33765309867759546\n",
      "Epoch: 5/5, Valid Loss: 0.5559585802257061\n",
      "Epoch: 5/5, Valid accuracy: 77.159%\n",
      "Model saved successfully\n",
      "\n",
      "Average valid accuracy: 0.7771587743732591\n"
     ]
    }
   ],
   "source": [
    "valid_acc_all = []\n",
    "for i in range(5):\n",
    "    print(\"k-fold validation: {}\".format(i))\n",
    "    train_loader, valid_loader = random_split_data(train_data, ratio=0.8)\n",
    "    model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    train(num_epochs=5, train_loader=train_loader, valid_loader=valid_loader, clip=5, interval=2500, valid_acc_all=valid_acc_all)\n",
    "print(\"Average valid accuracy: {}\".format(np.mean(valid_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRIv8xgGboB0"
   },
   "source": [
    "### hidden size=128, embedding size=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "jrdFRGb_bnLc"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim =400\n",
    "hidden_dim = 128\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KL-oc7UYb-_i",
    "outputId": "97288275-1d09-4c73-cde1-e5ae23fe0171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation: 0\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.7055128216743469\n",
      "Epoch: 1/5, Train Loss: 0.5742330858111382\n",
      "Epoch: 1/5, Valid Loss: 0.4743967851003011\n",
      "Epoch: 1/5, Valid accuracy: 75.487%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.4238418936729431\n",
      "Epoch: 2/5, Train Loss: 0.4699208450814088\n",
      "Epoch: 2/5, Valid Loss: 0.4842695916692416\n",
      "Epoch: 2/5, Valid accuracy: 77.994%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.22738242149353027\n",
      "Epoch: 3/5, Train Loss: 0.42285908152659735\n",
      "Epoch: 3/5, Valid Loss: 0.5085679888725281\n",
      "Epoch: 3/5, Valid accuracy: 76.045%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.37004488706588745\n",
      "Epoch: 4/5, Train Loss: 0.39532965379953383\n",
      "Epoch: 4/5, Valid Loss: 0.5667300696174303\n",
      "Epoch: 4/5, Valid accuracy: 76.323%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.23610080778598785\n",
      "Epoch: 5/5, Train Loss: 0.3745675835410754\n",
      "Epoch: 5/5, Valid Loss: 0.5840415954589844\n",
      "Epoch: 5/5, Valid accuracy: 73.538%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 1\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6863174438476562\n",
      "Epoch: 1/5, Train Loss: 0.5846507471005122\n",
      "Epoch: 1/5, Valid Loss: 0.4918430720766385\n",
      "Epoch: 1/5, Valid accuracy: 78.552%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.4158450663089752\n",
      "Epoch: 2/5, Train Loss: 0.48627906104922297\n",
      "Epoch: 2/5, Valid Loss: 0.5140882283449173\n",
      "Epoch: 2/5, Valid accuracy: 74.373%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.2984294295310974\n",
      "Epoch: 3/5, Train Loss: 0.44255684020121894\n",
      "Epoch: 3/5, Valid Loss: 0.5078059931596121\n",
      "Epoch: 3/5, Valid accuracy: 76.323%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.4916340112686157\n",
      "Epoch: 4/5, Train Loss: 0.4171419121225675\n",
      "Epoch: 4/5, Valid Loss: 0.5168169016639391\n",
      "Epoch: 4/5, Valid accuracy: 75.487%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.4033685326576233\n",
      "Epoch: 5/5, Train Loss: 0.3981942085325718\n",
      "Epoch: 5/5, Valid Loss: 0.5513005008300146\n",
      "Epoch: 5/5, Valid accuracy: 76.045%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 2\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6906478404998779\n",
      "Epoch: 1/5, Train Loss: 0.5697855698466301\n",
      "Epoch: 1/5, Valid Loss: 0.5179045448700587\n",
      "Epoch: 1/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.4503147304058075\n",
      "Epoch: 2/5, Train Loss: 0.4755574657221635\n",
      "Epoch: 2/5, Valid Loss: 0.5406844690442085\n",
      "Epoch: 2/5, Valid accuracy: 71.588%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.3460090756416321\n",
      "Epoch: 3/5, Train Loss: 0.4319096121986707\n",
      "Epoch: 3/5, Valid Loss: 0.5326603079835573\n",
      "Epoch: 3/5, Valid accuracy: 77.159%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.46611329913139343\n",
      "Epoch: 4/5, Train Loss: 0.4077782714714607\n",
      "Epoch: 4/5, Valid Loss: 0.552774245540301\n",
      "Epoch: 4/5, Valid accuracy: 75.487%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.26809942722320557\n",
      "Epoch: 5/5, Train Loss: 0.39241477627555527\n",
      "Epoch: 5/5, Valid Loss: 0.5657227312525114\n",
      "Epoch: 5/5, Valid accuracy: 73.259%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 3\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.69053715467453\n",
      "Epoch: 1/5, Train Loss: 0.6317335597276688\n",
      "Epoch: 1/5, Valid Loss: 0.5366166308522224\n",
      "Epoch: 1/5, Valid accuracy: 72.981%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.5331954956054688\n",
      "Epoch: 2/5, Train Loss: 0.5080872275233269\n",
      "Epoch: 2/5, Valid Loss: 0.5394330223401388\n",
      "Epoch: 2/5, Valid accuracy: 72.423%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.4299173653125763\n",
      "Epoch: 3/5, Train Loss: 0.4629624967078368\n",
      "Epoch: 3/5, Valid Loss: 0.49707920600970584\n",
      "Epoch: 3/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.36158376932144165\n",
      "Epoch: 4/5, Train Loss: 0.4361730814278126\n",
      "Epoch: 4/5, Valid Loss: 0.5405809804797173\n",
      "Epoch: 4/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.32944297790527344\n",
      "Epoch: 5/5, Train Loss: 0.42037906472881637\n",
      "Epoch: 5/5, Valid Loss: 0.5754705841342608\n",
      "Epoch: 5/5, Valid accuracy: 73.538%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 4\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6927823424339294\n",
      "Epoch: 1/5, Train Loss: 0.5778882484634718\n",
      "Epoch: 1/5, Valid Loss: 0.5095295657714208\n",
      "Epoch: 1/5, Valid accuracy: 75.209%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.4222278594970703\n",
      "Epoch: 2/5, Train Loss: 0.4804981034596761\n",
      "Epoch: 2/5, Valid Loss: 0.5107749054829279\n",
      "Epoch: 2/5, Valid accuracy: 74.930%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.4348955750465393\n",
      "Epoch: 3/5, Train Loss: 0.44219938410321874\n",
      "Epoch: 3/5, Valid Loss: 0.5794338832298914\n",
      "Epoch: 3/5, Valid accuracy: 74.652%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.29849424958229065\n",
      "Epoch: 4/5, Train Loss: 0.41914303868015607\n",
      "Epoch: 4/5, Valid Loss: 0.5474201142787933\n",
      "Epoch: 4/5, Valid accuracy: 72.702%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.5823878645896912\n",
      "Epoch: 5/5, Train Loss: 0.4002412092387676\n",
      "Epoch: 5/5, Valid Loss: 0.5494622985521952\n",
      "Epoch: 5/5, Valid accuracy: 74.930%\n",
      "Model saved successfully\n",
      "\n",
      "Average valid accuracy: 0.766016713091922\n"
     ]
    }
   ],
   "source": [
    "valid_acc_all = []\n",
    "for i in range(5):\n",
    "    print(\"k-fold validation: {}\".format(i))\n",
    "    train_loader, valid_loader = random_split_data(train_data, ratio=0.8)\n",
    "    model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    train(num_epochs=5, train_loader=train_loader, valid_loader=valid_loader, clip=5, interval=2500, valid_acc_all=valid_acc_all)\n",
    "print(\"Average valid accuracy: {}\".format(np.mean(valid_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4DZ86EzbpPb"
   },
   "source": [
    "### hidden size=512, embedding size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "zwJg-0HjbnNl"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim =100\n",
    "hidden_dim = 512\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKuBpdMhbnP9",
    "outputId": "605af732-482a-41af-b32a-adcb52ea2a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation: 0\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6905481815338135\n",
      "Epoch: 1/5, Train Loss: 0.6981073155005773\n",
      "Epoch: 1/5, Valid Loss: 0.6888065859675407\n",
      "Epoch: 1/5, Valid accuracy: 49.304%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6853047013282776\n",
      "Epoch: 2/5, Train Loss: 0.697849326968193\n",
      "Epoch: 2/5, Valid Loss: 0.686759427189827\n",
      "Epoch: 2/5, Valid accuracy: 52.646%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.6507456302642822\n",
      "Epoch: 3/5, Train Loss: 0.7078756774266561\n",
      "Epoch: 3/5, Valid Loss: 0.731641819079717\n",
      "Epoch: 3/5, Valid accuracy: 50.696%\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.6796683073043823\n",
      "Epoch: 4/5, Train Loss: 0.67979761048158\n",
      "Epoch: 4/5, Valid Loss: 0.7475843131542206\n",
      "Epoch: 4/5, Valid accuracy: 49.861%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.7133102416992188\n",
      "Epoch: 5/5, Train Loss: 0.6244572818080584\n",
      "Epoch: 5/5, Valid Loss: 0.6310108179847399\n",
      "Epoch: 5/5, Valid accuracy: 70.474%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 1\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6978480815887451\n",
      "Epoch: 1/5, Train Loss: 0.6985008000532786\n",
      "Epoch: 1/5, Valid Loss: 0.6926124691963196\n",
      "Epoch: 1/5, Valid accuracy: 49.304%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6917458772659302\n",
      "Epoch: 2/5, Train Loss: 0.6984751203854879\n",
      "Epoch: 2/5, Valid Loss: 0.6934830546379089\n",
      "Epoch: 2/5, Valid accuracy: 51.811%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.699282169342041\n",
      "Epoch: 3/5, Train Loss: 0.7029048132101695\n",
      "Epoch: 3/5, Valid Loss: 0.7130013753970464\n",
      "Epoch: 3/5, Valid accuracy: 50.975%\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.7233489751815796\n",
      "Epoch: 4/5, Train Loss: 0.7004117891788483\n",
      "Epoch: 4/5, Valid Loss: 0.708768313129743\n",
      "Epoch: 4/5, Valid accuracy: 51.532%\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.746999204158783\n",
      "Epoch: 5/5, Train Loss: 0.7122721990346909\n",
      "Epoch: 5/5, Valid Loss: 0.6839454770088196\n",
      "Epoch: 5/5, Valid accuracy: 54.039%\n",
      "\n",
      "k-fold validation: 2\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.693008303642273\n",
      "Epoch: 1/5, Train Loss: 0.6973407649993897\n",
      "Epoch: 1/5, Valid Loss: 0.6958351135253906\n",
      "Epoch: 1/5, Valid accuracy: 50.696%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6862550973892212\n",
      "Epoch: 2/5, Train Loss: 0.7017014447053274\n",
      "Epoch: 2/5, Valid Loss: 0.6889123767614365\n",
      "Epoch: 2/5, Valid accuracy: 49.582%\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.7107440233230591\n",
      "Epoch: 3/5, Train Loss: 0.7099094491799672\n",
      "Epoch: 3/5, Valid Loss: 0.6871244013309479\n",
      "Epoch: 3/5, Valid accuracy: 55.989%\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.7488906383514404\n",
      "Epoch: 4/5, Train Loss: 0.6885593393246333\n",
      "Epoch: 4/5, Valid Loss: 0.6819163486361504\n",
      "Epoch: 4/5, Valid accuracy: 56.546%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.6371792554855347\n",
      "Epoch: 5/5, Train Loss: 0.6865458534558614\n",
      "Epoch: 5/5, Valid Loss: 0.7541068196296692\n",
      "Epoch: 5/5, Valid accuracy: 52.646%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 3\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6938154697418213\n",
      "Epoch: 1/5, Train Loss: 0.7016610570351283\n",
      "Epoch: 1/5, Valid Loss: 0.6882355560859045\n",
      "Epoch: 1/5, Valid accuracy: 50.696%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.7153114676475525\n",
      "Epoch: 2/5, Train Loss: 0.6994465823173523\n",
      "Epoch: 2/5, Valid Loss: 0.693915456533432\n",
      "Epoch: 2/5, Valid accuracy: 47.911%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.6895484924316406\n",
      "Epoch: 3/5, Train Loss: 0.7031318312486012\n",
      "Epoch: 3/5, Valid Loss: 0.7064882119496664\n",
      "Epoch: 3/5, Valid accuracy: 51.811%\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.702006459236145\n",
      "Epoch: 4/5, Train Loss: 0.7074564954837164\n",
      "Epoch: 4/5, Valid Loss: 0.715193380912145\n",
      "Epoch: 4/5, Valid accuracy: 50.139%\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.6764625310897827\n",
      "Epoch: 5/5, Train Loss: 0.6920221274296443\n",
      "Epoch: 5/5, Valid Loss: 0.8211626932024956\n",
      "Epoch: 5/5, Valid accuracy: 53.760%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 4\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6924713850021362\n",
      "Epoch: 1/5, Train Loss: 0.6980713378190995\n",
      "Epoch: 1/5, Valid Loss: 0.6932656864325205\n",
      "Epoch: 1/5, Valid accuracy: 47.354%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.7024151682853699\n",
      "Epoch: 2/5, Train Loss: 0.6994634258349737\n",
      "Epoch: 2/5, Valid Loss: 0.6924397101004919\n",
      "Epoch: 2/5, Valid accuracy: 49.582%\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.7477959990501404\n",
      "Epoch: 3/5, Train Loss: 0.701369089047114\n",
      "Epoch: 3/5, Valid Loss: 0.6969892730315527\n",
      "Epoch: 3/5, Valid accuracy: 51.532%\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.7198210954666138\n",
      "Epoch: 4/5, Train Loss: 0.7090471484661103\n",
      "Epoch: 4/5, Valid Loss: 0.7176834146181742\n",
      "Epoch: 4/5, Valid accuracy: 50.975%\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.6268242597579956\n",
      "Epoch: 5/5, Train Loss: 0.6204980099201203\n",
      "Epoch: 5/5, Valid Loss: 0.6372446169455847\n",
      "Epoch: 5/5, Valid accuracy: 68.802%\n",
      "Model saved successfully\n",
      "\n",
      "Average valid accuracy: 0.607242339832869\n"
     ]
    }
   ],
   "source": [
    "valid_acc_all = []\n",
    "for i in range(5):\n",
    "    print(\"k-fold validation: {}\".format(i))\n",
    "    train_loader, valid_loader = random_split_data(train_data, ratio=0.8)\n",
    "    model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    train(num_epochs=5, train_loader=train_loader, valid_loader=valid_loader, clip=5, interval=2500, valid_acc_all=valid_acc_all)\n",
    "print(\"Average valid accuracy: {}\".format(np.mean(valid_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjD0AKlYbqN0"
   },
   "source": [
    "### hidden size=512, embedding size=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "j23DJqI9bnR8"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim =400\n",
    "hidden_dim = 512\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n5W1gw3bnWl",
    "outputId": "97f2cb57-9fc0-4b84-c119-757ebb642285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold validation: 0\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6969070434570312\n",
      "Epoch: 1/5, Train Loss: 0.6368362758755683\n",
      "Epoch: 1/5, Valid Loss: 0.5641574785113335\n",
      "Epoch: 1/5, Valid accuracy: 67.409%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.5850573778152466\n",
      "Epoch: 2/5, Train Loss: 0.5346089209318161\n",
      "Epoch: 2/5, Valid Loss: 0.5165652744472027\n",
      "Epoch: 2/5, Valid accuracy: 74.373%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.4991030693054199\n",
      "Epoch: 3/5, Train Loss: 0.4944921514689922\n",
      "Epoch: 3/5, Valid Loss: 0.4880125472942988\n",
      "Epoch: 3/5, Valid accuracy: 77.159%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.6507980227470398\n",
      "Epoch: 4/5, Train Loss: 0.469894880960385\n",
      "Epoch: 4/5, Valid Loss: 0.4722542588909467\n",
      "Epoch: 4/5, Valid accuracy: 77.159%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.4828230142593384\n",
      "Epoch: 5/5, Train Loss: 0.4537943410774072\n",
      "Epoch: 5/5, Valid Loss: 0.47007277607917786\n",
      "Epoch: 5/5, Valid accuracy: 76.880%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 1\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6945655345916748\n",
      "Epoch: 1/5, Train Loss: 0.6607527279655139\n",
      "Epoch: 1/5, Valid Loss: 0.5899744679530462\n",
      "Epoch: 1/5, Valid accuracy: 71.588%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.5171633362770081\n",
      "Epoch: 2/5, Train Loss: 0.5295181146065394\n",
      "Epoch: 2/5, Valid Loss: 0.5001129632194837\n",
      "Epoch: 2/5, Valid accuracy: 75.487%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.5995748043060303\n",
      "Epoch: 3/5, Train Loss: 0.48509439852833747\n",
      "Epoch: 3/5, Valid Loss: 0.48509764795502025\n",
      "Epoch: 3/5, Valid accuracy: 79.109%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.45199692249298096\n",
      "Epoch: 4/5, Train Loss: 0.45953196225563686\n",
      "Epoch: 4/5, Valid Loss: 0.4866163184245427\n",
      "Epoch: 4/5, Valid accuracy: 77.437%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.27000415325164795\n",
      "Epoch: 5/5, Train Loss: 0.4469998597204685\n",
      "Epoch: 5/5, Valid Loss: 0.4984186962246895\n",
      "Epoch: 5/5, Valid accuracy: 77.994%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 2\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6908801794052124\n",
      "Epoch: 1/5, Train Loss: 0.6545879648923874\n",
      "Epoch: 1/5, Valid Loss: 0.598969254642725\n",
      "Epoch: 1/5, Valid accuracy: 67.688%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.623392641544342\n",
      "Epoch: 2/5, Train Loss: 0.5437079493999482\n",
      "Epoch: 2/5, Valid Loss: 0.5108223681648573\n",
      "Epoch: 2/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.4402157664299011\n",
      "Epoch: 3/5, Train Loss: 0.4944814166824023\n",
      "Epoch: 3/5, Valid Loss: 0.4914880444606145\n",
      "Epoch: 3/5, Valid accuracy: 76.323%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.5819474458694458\n",
      "Epoch: 4/5, Train Loss: 0.4682553190390269\n",
      "Epoch: 4/5, Valid Loss: 0.5182002360622088\n",
      "Epoch: 4/5, Valid accuracy: 73.816%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.2597689628601074\n",
      "Epoch: 5/5, Train Loss: 0.45427540165185926\n",
      "Epoch: 5/5, Valid Loss: 0.49825963253776234\n",
      "Epoch: 5/5, Valid accuracy: 75.766%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 3\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.7000691890716553\n",
      "Epoch: 1/5, Train Loss: 0.6670026194453239\n",
      "Epoch: 1/5, Valid Loss: 0.6144417946537336\n",
      "Epoch: 1/5, Valid accuracy: 66.295%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.6156206727027893\n",
      "Epoch: 2/5, Train Loss: 0.5589776276946068\n",
      "Epoch: 2/5, Valid Loss: 0.5584400544563929\n",
      "Epoch: 2/5, Valid accuracy: 71.588%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.5926686525344849\n",
      "Epoch: 3/5, Train Loss: 0.5044047009547551\n",
      "Epoch: 3/5, Valid Loss: 0.5313870931665102\n",
      "Epoch: 3/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.5397534370422363\n",
      "Epoch: 4/5, Train Loss: 0.47897663483023645\n",
      "Epoch: 4/5, Valid Loss: 0.5379066367944082\n",
      "Epoch: 4/5, Valid accuracy: 74.095%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.40256285667419434\n",
      "Epoch: 5/5, Train Loss: 0.4590837301313877\n",
      "Epoch: 5/5, Valid Loss: 0.536216619114081\n",
      "Epoch: 5/5, Valid accuracy: 74.652%\n",
      "Model saved successfully\n",
      "\n",
      "k-fold validation: 4\n",
      "Train samples: 48000, Valid samples: 12000\n",
      "Epoch: 1/5, Step: 0/1500, Train Loss: 0.6926308274269104\n",
      "Epoch: 1/5, Train Loss: 0.7062107394138972\n",
      "Epoch: 1/5, Valid Loss: 0.7048500776290894\n",
      "Epoch: 1/5, Valid accuracy: 49.861%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/5, Step: 0/1500, Train Loss: 0.7021877765655518\n",
      "Epoch: 2/5, Train Loss: 0.7046446995735168\n",
      "Epoch: 2/5, Valid Loss: 0.709642211596171\n",
      "Epoch: 2/5, Valid accuracy: 53.482%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/5, Step: 0/1500, Train Loss: 0.7518576383590698\n",
      "Epoch: 3/5, Train Loss: 0.637165086845557\n",
      "Epoch: 3/5, Valid Loss: 0.6152308732271194\n",
      "Epoch: 3/5, Valid accuracy: 67.688%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/5, Step: 0/1500, Train Loss: 0.5355295538902283\n",
      "Epoch: 4/5, Train Loss: 0.5621335395375887\n",
      "Epoch: 4/5, Valid Loss: 0.562742792069912\n",
      "Epoch: 4/5, Valid accuracy: 74.930%\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 5/5, Step: 0/1500, Train Loss: 0.3852554261684418\n",
      "Epoch: 5/5, Train Loss: 0.5249446498950322\n",
      "Epoch: 5/5, Valid Loss: 0.5889163091778755\n",
      "Epoch: 5/5, Valid accuracy: 73.816%\n",
      "Model saved successfully\n",
      "\n",
      "Average valid accuracy: 0.7643454038997215\n"
     ]
    }
   ],
   "source": [
    "valid_acc_all = []\n",
    "for i in range(5):\n",
    "    print(\"k-fold validation: {}\".format(i))\n",
    "    train_loader, valid_loader = random_split_data(train_data, ratio=0.8)\n",
    "    model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    train(num_epochs=5, train_loader=train_loader, valid_loader=valid_loader, clip=5, interval=2500, valid_acc_all=valid_acc_all)\n",
    "print(\"Average valid accuracy: {}\".format(np.mean(valid_acc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XY8CRfsicOfI"
   },
   "source": [
    "## Best combination on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "QQ0afsBd3xyZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEerXO5hbnbn",
    "outputId": "fe1ba88b-3a9f-4a4c-b170-50405d6e458b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(19959, 100)\n",
       "  (rnn): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4xQ9eMLbWeP",
    "outputId": "ef99463c-8827-4df9-83b0-3424639e3bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4, Step: 0/1875, Train Loss: 0.6855311989784241\n",
      "Epoch: 1/4, Step: 800/1875, Train Loss: 0.6409757137298584\n",
      "Epoch: 1/4, Step: 1600/1875, Train Loss: 0.5881306529045105\n",
      "Epoch: 1/4, Train Loss: 0.6273406866709391\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 2/4, Step: 0/1875, Train Loss: 0.4047505855560303\n",
      "Epoch: 2/4, Step: 800/1875, Train Loss: 0.5136011838912964\n",
      "Epoch: 2/4, Step: 1600/1875, Train Loss: 0.6156495213508606\n",
      "Epoch: 2/4, Train Loss: 0.506865639368693\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 3/4, Step: 0/1875, Train Loss: 0.4363364577293396\n",
      "Epoch: 3/4, Step: 800/1875, Train Loss: 0.4549494981765747\n",
      "Epoch: 3/4, Step: 1600/1875, Train Loss: 0.25772589445114136\n",
      "Epoch: 3/4, Train Loss: 0.45821071407000225\n",
      "Model saved successfully\n",
      "\n",
      "Epoch: 4/4, Step: 0/1875, Train Loss: 0.3221054673194885\n",
      "Epoch: 4/4, Step: 800/1875, Train Loss: 0.49739134311676025\n",
      "Epoch: 4/4, Step: 1600/1875, Train Loss: 0.4270251393318176\n",
      "Epoch: 4/4, Train Loss: 0.4289244349161784\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=4, train_loader=train_loader, valid_loader=None, clip=5, interval=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uCTKUhqSudD",
    "outputId": "6cb52f53-ec7b-44a7-9841-27f87ab94746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.529\n",
      "Test accuracy: 76.602%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL7IfjIidRcN"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "k7o7l9SRfMb_"
   },
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "train_labels = []\n",
    "with open('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        label, text = line[0], line[5]\n",
    "        if label == '0':\n",
    "            train_sentences.append(text)\n",
    "            train_labels.append(0.)\n",
    "        if label == '4':\n",
    "            train_sentences.append(text)\n",
    "            train_labels.append(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjpvdbALdUOR",
    "outputId": "ab8f767b-f10e-465d-a28d-5cad86fc5a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      "10.0% done\n",
      "20.0% done\n",
      "30.0% done\n",
      "40.0% done\n",
      "50.0% done\n",
      "60.0% done\n",
      "70.0% done\n",
      "80.0% done\n",
      "90.0% done\n",
      "100% done\n",
      "vocab number: 247693\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word, train_data, test_data = process_data(train_sentences, train_labels, test_sentences, test_labels, padding_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "wb6q-0OTfh7n"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9bst7oIQ4J7",
    "outputId": "19f16a73-dbac-4745-d6d2-7c3bd249ca59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentNet(\n",
       "  (embedding): Embedding(247693, 400)\n",
       "  (rnn): LSTM(400, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, use_model='lstm', bidirectional=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.BCELoss()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRyfRdpvQ4MU",
    "outputId": "df69ef53-29fb-40f4-fc8a-ab41786a7566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1, Step: 0/50000, Train Loss: 0.6925088763237\n",
      "Epoch: 1/1, Step: 5000/50000, Train Loss: 0.7107133865356445\n",
      "Epoch: 1/1, Step: 10000/50000, Train Loss: 0.5370061993598938\n",
      "Epoch: 1/1, Step: 15000/50000, Train Loss: 0.5049312114715576\n",
      "Epoch: 1/1, Step: 20000/50000, Train Loss: 0.3669494390487671\n",
      "Epoch: 1/1, Step: 25000/50000, Train Loss: 0.3891751170158386\n",
      "Epoch: 1/1, Step: 30000/50000, Train Loss: 0.784136176109314\n",
      "Epoch: 1/1, Step: 35000/50000, Train Loss: 0.5021012425422668\n",
      "Epoch: 1/1, Step: 40000/50000, Train Loss: 0.5080928802490234\n",
      "Epoch: 1/1, Step: 45000/50000, Train Loss: 0.4689303934574127\n",
      "Epoch: 1/1, Train Loss: 0.5369125262585283\n",
      "Model saved successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=1, train_loader=train_loader, valid_loader=None, clip=5, interval=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4fDpowRQ4Oe",
    "outputId": "dc4a58ef-306f-4569-abdf-b13d0d0a7d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.498\n",
      "Test accuracy: 76.880%\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "M-Ay6i_TQ4Qj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "cUAKoXbDQ4TH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "Q3jRvoVDfh9o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qBFh6RFXKEHI"
   ],
   "name": "homework4 (2).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
